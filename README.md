# MOZART - Music Optimization Artificial intelligence

### Declaration: This is an open source project and in no case will the user be <i> <b> payable </b> </i>. If you discover anyone else distributing the exact same project in exchange for money kindly report to Github and <a href="mailto:work.naghimesh@gmail.com"> click on this link </a> to email me the same.

### Read My Paper: <a href="https://doi.org/10.1109/ICICT48043.2020.9112473"> Here </a>


Mozart, short for Music Optimization Artificial intelligence, is a state of the art technology that primarily focusses on the hefty problem of acoustic feature enhancements using learning mechanism and constraint optimizations.

As we already know that sound travels in waves, a source of vibration causes the molecules of the surrounding medium to oscillate back and forth causing the sound to travel in such wave patterns. A recording device, say a microphone, intercepts the sound waves from the surrounding medium’s excited molecules and acts as a transducer, that is, it converts one form of energy (sound) to another form (electrical energy). A human brain interprets sound in a similar fashion. It observes sound as vibrations and converts it into electrical impulses.

Another overwhelming nature of our brain is to act as a filter that can discriminate a type of sound from other sounds, like noises. Researchers have found out that this differentiation of sound from noise triggers a greater activity in the left half of our brain as it functions to “focus” on the wanted frequencies more than the unwanted frequencies. However, as researchers are still in the process of understanding this focus oriented brain function and analyse it using brain waves, we can make the use of the combination of science, mathematics and musicology to process audio in its waveform.
Machines don’t understand these impulses and so can not process them to generate optimized audio signals. Therefore we need to convert the signal into machine-understandable form. Such a conversion requires the signal to be converted from the voltage domain to binary.
For the robust processing that we aim to perform on audio, we need to understand that dealing with audio in binary is difficult as sound can not be binary. There are variables such as intensity (amplitude) of the signal where we simply cannot classify it to be present or not present. However, with more and more researches emerging to deal with signal processing and relating to musicology, we have some pre-defined libraries and tools that we can use to our utmost
 
advantage. Applications like ”Snapchat”, somewhat allows users to perform processing of both audio signals or images without requiring any knowledge of signal processing.
At this note, it is important to know that this research not only aims at designing a novel system for automating the lengthy process of audio signal processing but also aims at providing a better understanding of the creation of such sounds and also understand musicology to understand music creation networks


### Instructions:
##### Install Python 3, and Packages:
> Librosa <br/>
> Matplotlib <br/>
> Tensorflow <br/>
> Keras <br/>
> Numpy <br/>
> Scipy <br/>
> Sckit-learn<br/> 
> Pydub <br/>
> iPython <br/>
> Sklearn <br/>
> Glob <br/>
> Pandas<br/>


